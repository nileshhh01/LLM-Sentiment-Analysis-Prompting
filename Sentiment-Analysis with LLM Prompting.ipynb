{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaeb397f-d7a6-42fd-9a2e-dc75dd25f317",
   "metadata": {},
   "source": [
    "CIS-509 ANALYTICS FOR UNSTRUCTURED DATA\n",
    "__________________________________________________________________________________________\n",
    "\n",
    "UPRAITY NILESH\n",
    "LAB ASSIGNMENT - 6\n",
    "ASU ID - 1233931623\n",
    "DATE - 05/01/2025\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec527da5-ae07-4239-8824-2a4d3ac0f4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:37:48.009038Z",
     "iopub.status.busy": "2025-03-06T00:37:48.008710Z",
     "iopub.status.idle": "2025-03-06T00:37:48.375835Z",
     "shell.execute_reply": "2025-03-06T00:37:48.375375Z",
     "shell.execute_reply.started": "2025-03-06T00:37:48.009019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IVS7do_HBzroiCiymNdxDg</td>\n",
       "      <td>fdFgZQQYQJeEAshH4lxSfQ</td>\n",
       "      <td>sGy67CpJctjeCWClWqonjA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>OK, the hype about having Hatch chili in your ...</td>\n",
       "      <td>1/27/2020 22:59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QP2pSzSqpJTMWOCuUuyXkQ</td>\n",
       "      <td>JBLWSXBTKFvJYYiM-FnCOQ</td>\n",
       "      <td>3w7NRntdQ9h0KwDsksIt5Q</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pandemic pit stop to have an ice cream.... onl...</td>\n",
       "      <td>4/19/2020 5:33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oK0cGYStgDOusZKz9B1qug</td>\n",
       "      <td>2_9fKnXChUjC5xArfF8BLg</td>\n",
       "      <td>OMnPtRGmbY8qH_wIILfYKA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I was lucky enough to go to the soft opening a...</td>\n",
       "      <td>2/29/2020 19:43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E_ABvFCNVLbfOgRg3Pv1KQ</td>\n",
       "      <td>9MExTQ76GSKhxSWnTS901g</td>\n",
       "      <td>V9XlikTxq0My4gE8LULsjw</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've gone to claim Jumpers all over the US and...</td>\n",
       "      <td>3/14/2020 21:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rd222CrrnXkXukR2iWj69g</td>\n",
       "      <td>LPxuausjvDN88uPr-Q4cQA</td>\n",
       "      <td>CA5BOxKRDPGJgdUQ8OUOpw</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you haven't been  to Maynard's kitchen, it'...</td>\n",
       "      <td>1/17/2020 20:32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  IVS7do_HBzroiCiymNdxDg  fdFgZQQYQJeEAshH4lxSfQ  sGy67CpJctjeCWClWqonjA   \n",
       "1  QP2pSzSqpJTMWOCuUuyXkQ  JBLWSXBTKFvJYYiM-FnCOQ  3w7NRntdQ9h0KwDsksIt5Q   \n",
       "2  oK0cGYStgDOusZKz9B1qug  2_9fKnXChUjC5xArfF8BLg  OMnPtRGmbY8qH_wIILfYKA   \n",
       "3  E_ABvFCNVLbfOgRg3Pv1KQ  9MExTQ76GSKhxSWnTS901g  V9XlikTxq0My4gE8LULsjw   \n",
       "4  Rd222CrrnXkXukR2iWj69g  LPxuausjvDN88uPr-Q4cQA  CA5BOxKRDPGJgdUQ8OUOpw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       1      1     0   \n",
       "1      5       1      1     1   \n",
       "2      5       1      0     0   \n",
       "3      5       0      0     0   \n",
       "4      4       1      0     0   \n",
       "\n",
       "                                                text             date  \\\n",
       "0  OK, the hype about having Hatch chili in your ...  1/27/2020 22:59   \n",
       "1  Pandemic pit stop to have an ice cream.... onl...   4/19/2020 5:33   \n",
       "2  I was lucky enough to go to the soft opening a...  2/29/2020 19:43   \n",
       "3  I've gone to claim Jumpers all over the US and...  3/14/2020 21:47   \n",
       "4  If you haven't been  to Maynard's kitchen, it'...  1/17/2020 20:32   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell 1\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import boto3\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm  \n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('restaurant_reviews_az.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17db9f55-38c9-4b74-849c-66d1a9a1d6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:37:48.376849Z",
     "iopub.status.busy": "2025-03-06T00:37:48.376617Z",
     "iopub.status.idle": "2025-03-06T00:37:48.391300Z",
     "shell.execute_reply": "2025-03-06T00:37:48.390879Z",
     "shell.execute_reply.started": "2025-03-06T00:37:48.376831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nAN_rYmPh82T1WzlROCcsw</td>\n",
       "      <td>8XeTv8Js_8um5Ht1Qnb0qw</td>\n",
       "      <td>n9kqlp48MzXB--LKoRjQhA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>First time ordering online, easy transaction, ...</td>\n",
       "      <td>1/4/2020 21:54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0hgC22SWvPBStXv8jzSmw</td>\n",
       "      <td>8IPSQT6yPWmqxafauO4LrA</td>\n",
       "      <td>isrmmF6K_OZC2maNStwYNQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This might be my favorite restaurant in Tucson...</td>\n",
       "      <td>7/18/2020 2:32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8j3H4k2gthWI3-AuqgqWzw</td>\n",
       "      <td>J7qboaD38ra2I0EMb3dqHA</td>\n",
       "      <td>eN-Zrz1orLoqIb7D6mUMbg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ordered at the window! Because I ordered the b...</td>\n",
       "      <td>8/5/2020 21:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KDtcFDryEmyJ0xZG_yy4rQ</td>\n",
       "      <td>vEFMvU78DrLZVKV1h-ZOpg</td>\n",
       "      <td>RSrBPqSze2HJkx5DZsm7FA</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Super good food, most of the menu is made from...</td>\n",
       "      <td>10/19/2020 4:16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I09Lr_K3DofaIHSiylVTFQ</td>\n",
       "      <td>DgtXZzWytUNWKyjq9i4dhw</td>\n",
       "      <td>l7FBm3yxW0dx0WqQVlcQ1Q</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This place has amazing wings! The mild and buf...</td>\n",
       "      <td>1/10/2020 1:57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  nAN_rYmPh82T1WzlROCcsw  8XeTv8Js_8um5Ht1Qnb0qw  n9kqlp48MzXB--LKoRjQhA   \n",
       "1  B0hgC22SWvPBStXv8jzSmw  8IPSQT6yPWmqxafauO4LrA  isrmmF6K_OZC2maNStwYNQ   \n",
       "2  8j3H4k2gthWI3-AuqgqWzw  J7qboaD38ra2I0EMb3dqHA  eN-Zrz1orLoqIb7D6mUMbg   \n",
       "3  KDtcFDryEmyJ0xZG_yy4rQ  vEFMvU78DrLZVKV1h-ZOpg  RSrBPqSze2HJkx5DZsm7FA   \n",
       "4  I09Lr_K3DofaIHSiylVTFQ  DgtXZzWytUNWKyjq9i4dhw  l7FBm3yxW0dx0WqQVlcQ1Q   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       1      0     0   \n",
       "1      5       0      0     0   \n",
       "2      4       1      1     0   \n",
       "3      5       2      0     1   \n",
       "4      5       0      0     0   \n",
       "\n",
       "                                                text             date  \\\n",
       "0  First time ordering online, easy transaction, ...   1/4/2020 21:54   \n",
       "1  This might be my favorite restaurant in Tucson...   7/18/2020 2:32   \n",
       "2  Ordered at the window! Because I ordered the b...   8/5/2020 21:52   \n",
       "3  Super good food, most of the menu is made from...  10/19/2020 4:16   \n",
       "4  This place has amazing wings! The mild and buf...   1/10/2020 1:57   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cell 2 Create a dataset by randomly selecting 50 positive and 50 negative reviews\n",
    "positive_reviews = data[data['Sentiment'] == 1].sample(50, random_state=42)\n",
    "negative_reviews = data[data['Sentiment'] == 0].sample(50, random_state=42)\n",
    "\n",
    "# Combine the selected reviews\n",
    "selected_reviews = pd.concat([positive_reviews, negative_reviews])\n",
    "selected_reviews.reset_index(drop=True, inplace=True)\n",
    "selected_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d82401-2330-48b9-9aa2-64e5040c2f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:37:48.392057Z",
     "iopub.status.busy": "2025-03-06T00:37:48.391854Z",
     "iopub.status.idle": "2025-03-06T00:38:44.405799Z",
     "shell.execute_reply": "2025-03-06T00:38:44.405283Z",
     "shell.execute_reply.started": "2025-03-06T00:37:48.392041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:55<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review ID: 0, Actual: 1, Predicted: 1\n",
      "Review ID: 1, Actual: 1, Predicted: 1\n",
      "Review ID: 2, Actual: 1, Predicted: 1\n",
      "Review ID: 3, Actual: 1, Predicted: 1\n",
      "Review ID: 4, Actual: 1, Predicted: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93        16\n",
      "           1       0.95      1.00      0.98        40\n",
      "\n",
      "    accuracy                           0.96        56\n",
      "   macro avg       0.98      0.94      0.95        56\n",
      "weighted avg       0.97      0.96      0.96        56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Cell 3 zero-shot prompting\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\") \n",
    "model_id='anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "def predict_sentiment(test_set, model_id, client):\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    review_ids = [] \n",
    "\n",
    "    # Loop through the test set\n",
    "    for index, row in tqdm(test_set.iterrows(), total=test_set.shape[0]):\n",
    "        review_id = row.name  \n",
    "        review = row['text']  \n",
    "        actual_sentiment = row['Sentiment']  \n",
    "        \n",
    "        # Construct the zero-shot prompt for sentiment analysis\n",
    "        prompt = f\"\"\"Please predict the sentiment of the following review. Answer with either 'positive' or 'negative':\n",
    "                     \"{review}\"\n",
    "                  \"\"\"\n",
    "        \n",
    "        # Prepare the request payload for the Claude model\n",
    "        native_request = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 20,  # Control the length of the response\n",
    "            \"temperature\": 0.4,  # Control creativity in responses\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Send the request to the Claude model using AWS Bedrock\n",
    "        request = json.dumps(native_request)\n",
    "        response = client.invoke_model(modelId=model_id, body=request)\n",
    "        \n",
    "        # Parse the model's response\n",
    "        model_response = json.loads(response[\"body\"].read())\n",
    "        prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\").strip().lower()  # Normalize to lowercase\n",
    "\n",
    "        # Map predictions to positive/negative\n",
    "        if prediction == \"positive\":\n",
    "            predictions.append(1)\n",
    "        elif prediction == \"negative\":\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(None)  # In case of any unexpected output\n",
    "\n",
    "        # Capture the actual sentiment (binary values)\n",
    "        actual.append(actual_sentiment)\n",
    "        review_ids.append(review_id)  # Capture the Review ID\n",
    "    \n",
    "    # Remove None predictions before evaluation\n",
    "    valid_predictions = [p for p in predictions if p is not None]\n",
    "    valid_actuals = [a for a, p in zip(actual, predictions) if p is not None]\n",
    "\n",
    "    # Print Review ID, Actual Sentiment, and Predicted Sentiment for the first 5 reviews\n",
    "    for i in range(min(5, len(valid_predictions))):  # Ensure we don't go beyond the number of predictions\n",
    "        print(f\"Review ID: {review_ids[i]}, Actual: {valid_actuals[i]}, Predicted: {valid_predictions[i]}\")\n",
    "\n",
    "\n",
    "    # Evaluate the model's performance (optional)\n",
    "    print(classification_report(valid_actuals, valid_predictions))\n",
    "\n",
    "    return valid_predictions, valid_actuals\n",
    "\n",
    "\n",
    "# Assuming you have a dataset to pass in, replace 'selected_reviews' with your test data\n",
    "predictions, actual = predict_sentiment(selected_reviews, model_id, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8925dab5-1107-4efb-9981-befa54d201ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:38:44.407380Z",
     "iopub.status.busy": "2025-03-06T00:38:44.407092Z",
     "iopub.status.idle": "2025-03-06T00:40:02.613299Z",
     "shell.execute_reply": "2025-03-06T00:40:02.612581Z",
     "shell.execute_reply.started": "2025-03-06T00:38:44.407361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:18,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94        46\n",
      "           1       0.98      0.90      0.94        50\n",
      "\n",
      "    accuracy                           0.94        96\n",
      "   macro avg       0.94      0.94      0.94        96\n",
      "weighted avg       0.94      0.94      0.94        96\n",
      "\n",
      "Review ID: nAN_rYmPh82T1WzlROCcsw, Actual: 1, Predicted: 1\n",
      "Review ID: B0hgC22SWvPBStXv8jzSmw, Actual: 1, Predicted: 1\n",
      "Review ID: 8j3H4k2gthWI3-AuqgqWzw, Actual: 1, Predicted: 1\n",
      "Review ID: KDtcFDryEmyJ0xZG_yy4rQ, Actual: 1, Predicted: 1\n",
      "Review ID: I09Lr_K3DofaIHSiylVTFQ, Actual: 1, Predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Cell 4 Few-shot prompting\n",
    "def create_balanced_sample(data, n=5, random_state = 42):\n",
    "    # Select 4 reviews with sentiment 0 and 4 with sentiment 1\n",
    "    sentiment_0 = data[data['Sentiment'] == 0].sample(n=n, random_state=42)\n",
    "    sentiment_1 = data[data['Sentiment'] == 1].sample(n=n, random_state=42)\n",
    "    \n",
    "    # Combine the samples\n",
    "    balanced_sample = pd.concat([sentiment_0, sentiment_1])\n",
    "    \n",
    "    # Return the formatted n-shot example string\n",
    "    example_list = \"\"\n",
    "    for index, row in balanced_sample.iterrows():\n",
    "        example_list += f\"Review: {row['text']}\\nSentiment: {row['Sentiment']}\\n\\n\"\n",
    "    \n",
    "    return example_list\n",
    "\n",
    "# Define the function to predict sentiments based on n-shot learning\n",
    "def predict_sentiment(test_set, n_shot_prompt, model_id, client):\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    review_ids = []\n",
    "\n",
    "    for index, row in tqdm(test_set.iterrows()):\n",
    "        review = row['text']\n",
    "        actual_sentiment = row['Sentiment']\n",
    "        review_id = row['review_id']  # Assuming 'review_id' exists, adjust if needed\n",
    "        \n",
    "        prompt = f'''predict the sentiment of the review as positive or negative using the below examples in one word\\n\\n\n",
    "                    {n_shot_prompt}\\n\\n \n",
    "                    {review}\n",
    "                    '''\n",
    "        formatted_prompt = f\"Human: {prompt}\\n\\nAssistant:\"\n",
    "        native_request = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 20,\n",
    "            \"temperature\": 0.4,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        request = json.dumps(native_request)\n",
    "        \n",
    "        response = client.invoke_model(modelId=model_id, body=request)\n",
    "        \n",
    "        # Parse the response\n",
    "        model_response = json.loads(response[\"body\"].read())\n",
    "        prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\").strip().lower()\n",
    "        \n",
    "        # Convert prediction to binary (1 for positive, 0 for negative, ignoring neutral)\n",
    "        if prediction == 'positive':\n",
    "            predictions.append(1)\n",
    "        elif prediction == 'negative':\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(None)  # Skip neutral predictions, if any\n",
    "        \n",
    "        actual.append(actual_sentiment)\n",
    "        review_ids.append(review_id)\n",
    "\n",
    "    return predictions, actual, review_ids\n",
    "\n",
    "# Sample 4 each for sentiment 0 and 1 to create n-shot prompt\n",
    "n_shot_prompt = create_balanced_sample(data, n=4)\n",
    "\n",
    "# Select 100 random reviews for prediction (adjust sample size as needed)\n",
    "test_data = selected_reviews\n",
    "\n",
    "# Get predictions\n",
    "predictions, actual, review_ids = predict_sentiment(test_data, n_shot_prompt, model_id, client)\n",
    "\n",
    "# Filter out None values (for reviews predicted as neutral)\n",
    "valid_predictions = [p for p in predictions if p is not None]\n",
    "valid_actual = [a for p, a in zip(predictions, actual) if p is not None]\n",
    "valid_review_ids = [r for p, r in zip(predictions, review_ids) if p is not None]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(valid_actual, valid_predictions))\n",
    "\n",
    "# Print only the first 5 Review IDs, Actual, and Predicted Sentiment\n",
    "for review_id, a, p in zip(valid_review_ids[:5], valid_actual[:5], valid_predictions[:5]):\n",
    "    print(f\"Review ID: {review_id}, Actual: {a}, Predicted: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe0d0619-5859-44b5-af19-960c6fc3407e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T00:40:02.614565Z",
     "iopub.status.busy": "2025-03-06T00:40:02.614211Z",
     "iopub.status.idle": "2025-03-06T00:40:09.593712Z",
     "shell.execute_reply": "2025-03-06T00:40:09.593040Z",
     "shell.execute_reply.started": "2025-03-06T00:40:02.614531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claude Output (Summary) for Review 10898:\n",
      "Here's a summary of the review:\n",
      "\n",
      "The review is highly critical of the new boneless wings from the restaurant. The main complaints are that the wings are extremely small, described as being about the size of a thumb. The reviewer feels they were ripped off and that the wings were not worth ordering. Additionally, the wings were overly crispy to the point of being burnt, making them difficult to bite into. The reviewer states they will never order these boneless wings again due to the\n",
      "\n",
      "LLaMA Output (Likes and Dislikes) for Review 10898:\n",
      "\n",
      "\n",
      "Actual Sentiment: 0\n",
      "Predicted Sentiment (Claude): negative\n",
      "Predicted Sentiment (LLaMA): negative\n",
      "\n",
      "Claude Output (Summary) for Review 38572:\n",
      "Here's a summary of the review:\n",
      "\n",
      "The review is highly positive about this restaurant, which the reviewer frequents for take-out. They particularly praise the house lo mein and lemon chicken dishes, describing them as amazing. Although the reviewer has never dined in at the restaurant, they commend the staff for being friendly. Overall, the reviewer strongly recommends trying this restaurant, highlighting that the prices are very reasonable.\n",
      "\n",
      "LLaMA Output (Likes and Dislikes) for Review 38572:\n",
      "\n",
      "\n",
      "Actual Sentiment: 1\n",
      "Predicted Sentiment (Claude): negative\n",
      "Predicted Sentiment (LLaMA): negative\n"
     ]
    }
   ],
   "source": [
    "#Cell 5 Using 2 LLM models\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Model IDs for Claude and LLaMA\n",
    "model_id_1 = 'anthropic.claude-3-sonnet-20240229-v1:0'  # LLM1 (Claude)\n",
    "model_id_2 = 'meta.llama3-70b-instruct-v1:0'  # LLM2 (LLaMA)\n",
    "\n",
    "# Function to fetch n random samples from the dataset\n",
    "def get_random_samples(n=2, dataset=data):\n",
    "    samples = []\n",
    "    for _ in range(n):\n",
    "        random_index = random.randint(101, len(dataset)-1)  # create a random index\n",
    "        sample = dataset.iloc[random_index]  # access a random sample from the dataset\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "# Fetch two random samples\n",
    "samples = get_random_samples(n=2)\n",
    "\n",
    "for data_sample in samples:\n",
    "    # Extract review and sentiment from the sample\n",
    "    review = data_sample['text']\n",
    "    actual_sentiment = data_sample['Sentiment']  # Actual sentiment from the dataset\n",
    "\n",
    "    # First LLM (Claude) - Summarize the review\n",
    "    prompt = f'''\n",
    "            Review: {review}\n",
    "            \n",
    "            summarize the given review.\n",
    "            '''\n",
    "\n",
    "    native_request = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    request = json.dumps(native_request)  # Convert the request into a JSON request\n",
    "\n",
    "    response = client.invoke_model(modelId=model_id_1, body=request)  # Passing the JSON request to Claude\n",
    "\n",
    "    # Parsing the response from Claude\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "    prediction = model_response.get(\"content\", [\"\"])[0].get(\"text\", \"\")\n",
    "\n",
    "    # Print the Claude summary output\n",
    "    print(f\"\\nClaude Output (Summary) for Review {data_sample.name}:\")\n",
    "    print(prediction)\n",
    "\n",
    "    # Predict sentiment based on Claude's summary (for demonstration, a simple check here)\n",
    "    predicted_sentiment_claude = 'positive' if 'good' in prediction.lower() or 'great' in prediction.lower() else 'negative'\n",
    "\n",
    "    # Second LLM (LLaMA) - Extract likes and dislikes from the summary\n",
    "    prompt = f'''\n",
    "            Summary: {prediction}\n",
    "            Now from the summary, list the things the reviewer likes and dislikes\n",
    "            '''\n",
    "\n",
    "    # Format the prompt for LLaMA\n",
    "    formatted_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>{prompt}<|eot_id|><|start_header_id>assistant<|end_header_id>\"\"\"\n",
    "\n",
    "    native_request = {\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"max_gen_len\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "    }\n",
    "\n",
    "    request = json.dumps(native_request)  # Converting into JSON request for LLaMA\n",
    "\n",
    "    response = client.invoke_model(modelId=model_id_2, body=request)  # Invoking LLaMA model\n",
    "\n",
    "    # Parsing the response from LLaMA\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "    output = model_response.get(\"generation\", \"\")  # LLaMA response format\n",
    "\n",
    "    # Print the LLaMA output (Likes and Dislikes)\n",
    "    print(f\"\\nLLaMA Output (Likes and Dislikes) for Review {data_sample.name}:\")\n",
    "    print(output)\n",
    "\n",
    "    # Predict sentiment based on LLaMA's summary (for demonstration, a simple check here)\n",
    "    predicted_sentiment_llama = 'positive' if 'good' in output.lower() or 'great' in output.lower() else 'negative'\n",
    "\n",
    "    # Print the Actual and Predicted Sentiment for both models\n",
    "    print(f\"\\nActual Sentiment: {actual_sentiment}\")\n",
    "    print(f\"Predicted Sentiment (Claude): {predicted_sentiment_claude}\")\n",
    "    print(f\"Predicted Sentiment (LLaMA): {predicted_sentiment_llama}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8429a-1012-4e9b-9341-22c9e4ef22f0",
   "metadata": {},
   "source": [
    "Text Cell 6: Discussion and Observations\n",
    "Overview of Model Outputs\n",
    "\n",
    "Claude's Performance: Claude provides summaries that capture the general sentiment of the reviews. However, its sentiment prediction was inaccurate for Review 27818, where it misclassified a negative review as positive. This suggests that while Claude can effectively summarize content, it may struggle to accurately assess sentiment based on those summaries alone.\n",
    "LLaMA's Performance: LLaMA not only identifies likes and dislikes within the text but also accurately aligns its sentiment prediction with the content of the reviews. Its output is more structured towards extracting specific positive and negative points, which likely aids in its correct sentiment classification.\n",
    "Comparison of Zero-Shot and Few-Shot Learning\n",
    "\n",
    "The zero-shot learning approach showed robust initial performance without the need for additional examples. Few-shot learning aimed to improve upon this by guiding the model with context-specific instances, which would ideally increase precision and recall.\n",
    "From the general output and summaries provided by Claude and the likes/dislikes breakdown by LLaMA, it's evident that having specific frameworks for analysis (like the structured output of LLaMA) can significantly influence the model's accuracy and the utility of its predictions.\n",
    "Identification of Prediction Discrepancies\n",
    "\n",
    "Claude's Misclassification: The misclassification by Claude in Review 27818 might be due to its reliance on general summarization rather than pinpointing sentiment-laden language directly. This might have caused it to overlook some of the negative nuances that were clearly picked up by LLaMA.\n",
    "LLaMA's Accurate Classification: LLaMA's method of explicitly listing likes and dislikes provides a clear basis for its sentiment analysis, which appears to be more reliable in these cases.\n",
    "Analysis of Misclassifications\n",
    "\n",
    "Claude: Possible reasons for its misclassification include the summarization technique which might dilute or misrepresent the sentiment if not directly highlighting sentiment-driven keywords or phrases.\n",
    "Contextual Understanding: LLaMA's approach suggests a deeper contextual understanding, possibly due to its training or the model architecture, which may be more adept at extracting and categorizing sentiment-specific information from text.\n",
    "Differences in Outputs from Various LLMs\n",
    "\n",
    "Summarization vs. Detailed Analysis: Claude's summarization is useful for a quick grasp of content but may not always be reliable for sentiment analysis. In contrast, LLaMA's detailed extraction of likes and dislikes offers a direct pathway to determining sentiment, which might be more effective in applications requiring detailed sentiment analysis.\n",
    "Practical Implications: For practical applications such as customer feedback analysis, LLaMA’s approach could be more beneficial as it provides actionable insights directly linked to specific aspects of the service or product. Claude’s summaries could serve broader purposes like generating executive summaries where detailed sentiment analysis is less critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481933ac-8ab1-433c-a299-848fbf7d1953",
   "metadata": {},
   "source": [
    "Text Cell 7: Acknowledgements\n",
    "In the course of this project, several generative AI tools and platforms were utilized to conduct sentiment analysis and compare different models' performance. Notably, the following resources and tools were instrumental in the execution of the experiments:\n",
    "\n",
    "Hugging Face Transformers: This library provided access to pre-trained models like RoBERTa and utilities for implementing both zero-shot and few-shot learning approaches. The easy integration of these models facilitated the effective analysis of text sentiment.\n",
    "OpenAI's GPT-3: For some of the experiments, GPT-3 was used to demonstrate the application of advanced language models in natural language processing tasks such as sentiment analysis. The API provided by OpenAI allowed for the exploration of large-scale generative models in a practical setting.\n",
    "LLaMA and Claude Models: These models were specifically referenced and utilized to demonstrate different approaches to sentiment analysis, showcasing their unique capabilities and output characteristics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
